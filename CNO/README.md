## Observability Fundamental

So what is observability? Observability is the ability to understand and measure the state of a system based upon data generated by the system. And what observability allows you to do is it allows you to generate actionable outputs from unexpected scenarios in highly dynamic environments. And some of the benefits of observability or implementing observability in your application or infrastructure are it's going to give you better insights into the internal workings of your system or application. It's going to help speed up troubleshooting. You'll be able to detect hard-to-catch problems, and you'll be able to monitor the performance of your application and how it's performing, as well as improve cross-team collaboration. So observability is just there to help us better understand the internals of our system. Because without observability, our application is going to operate like a black box. Some data goes in and some data goes out. We don't have any idea what's going on inside. It's just a black box. But what if we peel back the curtains to get a complete picture of how all of the individual blocks of our system operate together so that if something goes wrong or, correction, when something goes wrong, we know exactly what component failed and why. And that's really what observability is trying to do for us. Over time, we're starting to see that architectures for applications and systems are starting to become more and more complex. And this is especially true with microservices. And as more and more companies adopt microservices, there's a greater need for observability within them. And that's because with a traditional monolith, you just have one application really, just one entity where you can take a look at all of the logs, all of the data. With a microservices architecture, you now have so many different individual components and pieces that are all working together. And troubleshooting issues is not quite as simple because now we have to isolate the specific component. We have to figure out how it got into that state. We got to figure out how all of the other pieces fit together to understand why something happened. When it comes to troubleshooting issues, we need more information than just what is wrong. We need to know why our application entered a specific state, what component is responsible, and how we can prevent this in the future. So we want to know why our error rates rising? Why is there high latency? Why are services timing out? We don't just want to know what the symptom is. We need to understand why. And observability is going to give us the flexibility to understand these unpredictable events. So how do we accomplish observability? There are three main pillars to configuring observability within your application. You're going to have logging, you're going to have metrics, and you're going to have traces. Now when it comes to logs, logs are nothing more than just records of events that have occurred and encapsulate information about that specific event. We've all seen logs, whether it's operating system logs, application logs, database logs. It's pretty straightforward, but there are two main components to a log. You're going to have the timestamp of when the event occurred, and you're going to have a message containing information about the specific event. Now logs are usually the most common form of observability produced by a system. Even if you don't have any kind of observability, usually they're going to have some form of logging within your application or your system. However, logging isn't necessarily the best way to troubleshoot issues, and that's because of the verbosity of some logs. If you are experiencing some sort of outage of some kind, sifting through all of those verbose logs can be very difficult to actually pinpoint what happened. In addition to that, logs of processes are likely to be interwoven with other concurrent processes, spread across multiple systems, thus further complicating the output thatâ€™s being produced by them. Now traces are a little bit different than logs. Traces actually allow you to follow operations as they traverse through various systems and services. And so what they ultimately do is they help you follow an individual request and see it flow through your system hop by hop. And this is really where you get to understand how everything fits together in your application. You can send a request through your application and watch it go step by step through each service, through each layer, and see how all of them fit together. Each trace is going to have a trace ID that can be used to identify a specific request as it traverses the system. And individual events that form a trace are called spans. So at each layer or component or service within our application, that's going to represent an event. So at the gateway, you're going to have one span. At the off layer, you're going to have another span. As it goes to the user layer, you're going to have a span and then going to the database as well. And a span is going to track a couple of things. The start time, you're also going to have the duration, how long did we spend there. And you're also going to have the parent ID, so what was responsible for triggering this specific span. And all of these different components or these spans are going to make up the entirety of the trace. Now the last pillar for observability is metrics. And metrics provide us information about the state of a system using numerical values, which is a little bit different than logs. Logs usually provide text and a few other things. Metrics are purely numerical data. So it's going to contain information like what is the CPU load or what are the number of open files on a system. What's the HTTP response time of an API? What are the number of errors in our application? So those are all things that we would track with metrics. And the data that's collected can also be aggregated over time and graphed using visualization tools to identify trends over time. Now metrics are going to contain four pieces of information. The first thing is going to be the metric name. This is just the name of the specific metric that you're collecting. And usually it's going to provide a decent description of what it actually represents. You're going to have a value for the metric. So what was the most recent or current value for the specific metric? You're going to have a timestamp for the metric. And the timestamp is just going to be when did we actually collect this specific metric or this piece of information. And then we're also going to have dimensions, which just carry additional information about this specific metric. So we have our three pillars of observability. Now this course is about Prometheus. So it's important to understand where Prometheus falls within the observability tree. And Prometheus is specifically a monitoring solution that's responsible for collecting and aggregating metrics. So it is part of the metrics branch. And so moving forward, it's important to understand that Prometheus only handles metrics. It does nothing with logs and it does nothing with traces. You need to use different applications to get those other aspects of observability within your system. 


WEBVTT Hello, and welcome to this lecture. In this lecture, we look at the different ways of manually scheduling a pod on a node. What do you do when you do not have a scheduler in your cluster? You probably do not want to rely on the built-in scheduler, and instead want to schedule the pods yourself. So how exactly does a scheduler work in the backend? Let's start with a simple pod definition file. Every pod has a field called node name that by default is not set. You don't typically specify this field when you create the pod manifest file. Kubernetes adds it automatically, the scheduler goes through all the pods and looks for those that do not have this property set. Those are the candidates for scheduling. It then identifies the right node for the pod by running the scheduling algorithm. Once identified, it schedules the pod on the node by setting the node name property to the name of the node by creating a binding object. So if there is no scheduler to monitor and schedule nodes, what happens, the pods continue to be in a pending state. So what can you do about it, you can manually assign pods to nodes yourself. Well, without a scheduler, the easiest way to schedule a pod is to simply set the node name field to the name of the node in your pod specification file. While creating the pod, the pod then gets assigned to the specified node, you can only specify the node name at creation time. What if the pod is already created, and you want to assign the pod to a node. Kubernetes won't allow you to modify the node name property of a pod. So another way to assign a node to an existing pod is to create a binding object and send a POST request to the pod's binding API, thus mimicking what the actual scheduler does. In the binding object, you specify a target node with the name of the node, then send a POST request to the pod's binding API with the data set to the binding object in a JSON format. So you must convert the YAML file into its equivalent JSON form. 
